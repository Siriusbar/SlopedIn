<p align="center">
  <img src="icons/icon128.png" alt="SlopedIn Logo" width="100" />
</p>

<h1 align="center">SlopedIn</h1>

<p align="center">
  <strong>AI Content Detector for LinkedIn</strong><br/>
  A Chrome extension that flags AI-generated posts directly in your feed â€” 100% local, zero data leaves your browser.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/manifest-v3-blue" alt="Manifest V3" />
  <img src="https://img.shields.io/badge/inference-local-green" alt="Local Inference" />
  <img src="https://img.shields.io/badge/license-MIT-yellow" alt="MIT License" />
</p>

---

## âœ¨ Features

- ğŸ” **Real-time detection** â€” scans LinkedIn posts as you scroll
- ğŸ§  **Local AI inference** â€” runs a RoBERTa model entirely in your browser via [Transformers.js](https://huggingface.co/docs/transformers.js)
- ğŸ”’ **Privacy first** â€” no data sent to external servers, ever
- ğŸ·ï¸ **Visual badges** â€” color-coded labels on each post (ğŸŸ¢ Human Â· ğŸ”´ AI-generated)
- âš¡ **Toggle on/off** â€” enable or disable detection from the popup

<!-- ## ğŸ–¥ï¸ Screenshots

| Popup | Feed Badge |
|-------|------------|
| Clean dark-mode popup with on/off toggle | Posts get a colored badge with confidence score | -->

## ğŸ—ï¸ Architecture

```
LinkedIn Tab                     Extension (background)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   message    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ content.js  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚ background.js          â”‚
â”‚ (DOM scan)  â”‚              â”‚ (service worker)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚ message
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚ offscreen.html          â”‚
                             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                             â”‚ â”‚ offscreen.js        â”‚  â”‚
                             â”‚ â”‚ Transformers.js     â”‚  â”‚
                             â”‚ â”‚ + ONNX Runtime WASM â”‚  â”‚
                             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **content.js** â€” observes the LinkedIn DOM, extracts post text, injects badges
- **background.js** â€” service worker that manages the offscreen document lifecycle
- **offscreen.js** â€” loads the AI model and runs inference using ONNX Runtime (WebAssembly)
- **worker.js** â€” standalone inference worker (unused in current architecture, kept for reference)

## ğŸš€ Installation

### Prerequisites
- Google Chrome (v116+)
- Node.js & npm (only needed to rebuild the bundle)

### Load as unpacked extension

1. **Clone the repo**
   ```bash
   git clone https://github.com/Siriusbar/SlopedIn.git
   cd SlopedIn
   ```

2. **Install dependencies** (for bundled library)
   ```bash
   npm install
   ```

3. **Open Chrome** and navigate to `chrome://extensions`

4. Enable **Developer mode** (top-right toggle)

5. Click **Load unpacked** and select the `SlopedIn` directory

6. Navigate to [linkedin.com](https://www.linkedin.com/feed/) â€” posts will be scanned automatically

> **Note:** The first run downloads the AI model (~120 MB) from HuggingFace. This is cached by the browser for subsequent loads.

## âš™ï¸ How It Works

1. `content.js` uses a `MutationObserver` to detect new posts in the LinkedIn feed
2. Post text is extracted and sent to `background.js` via `chrome.runtime.sendMessage`
3. `background.js` forwards the request to an offscreen document
4. `offscreen.js` runs the [`onnx-community/roberta-base-openai-detector-ONNX`](https://huggingface.co/onnx-community/roberta-base-openai-detector-ONNX) model using Transformers.js with ONNX Runtime (WASM backend)
5. The result (label + confidence) is sent back and displayed as a badge on the post

## ğŸ“ Project Structure

```
SlopedIn/
â”œâ”€â”€ manifest.json          # Chrome extension manifest (MV3)
â”œâ”€â”€ background.js          # Service worker â€“ offscreen doc lifecycle
â”œâ”€â”€ offscreen.html         # Hosts the inference script
â”œâ”€â”€ offscreen.js           # AI model loading & inference
â”œâ”€â”€ content.js             # DOM observation & badge injection
â”œâ”€â”€ styles.css             # Badge styling
â”œâ”€â”€ popup.html             # Extension popup UI
â”œâ”€â”€ popup.js               # Toggle enable/disable
â”œâ”€â”€ worker.js              # Standalone worker (reference)
â”œâ”€â”€ icons/
â”‚   â”œâ”€â”€ icon.svg           # Source icon
â”‚   â”œâ”€â”€ icon16.png
â”‚   â”œâ”€â”€ icon48.png
â”‚   â””â”€â”€ icon128.png
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ transformers.bundle.js              # Bundled Transformers.js + ONNX Runtime
â”‚   â”œâ”€â”€ ort-wasm-simd-threaded.jsep.mjs     # ONNX WASM JS proxy
â”‚   â””â”€â”€ ort-wasm-simd-threaded.jsep.wasm    # ONNX WASM binary (~22 MB)
â””â”€â”€ package.json
```

## ğŸ”§ Rebuilding the Bundle

If you need to update Transformers.js or ONNX Runtime:

```bash
# Install/update dependencies
npm install @huggingface/transformers@latest

# Bundle with esbuild
npx esbuild node_modules/@huggingface/transformers/src/transformers.js \
  --bundle --format=esm --outfile=lib/transformers.bundle.js \
  --platform=browser --target=es2020 --minify

# Copy ONNX runtime files
cp node_modules/onnxruntime-web/dist/ort-wasm-simd-threaded.jsep.mjs lib/
cp node_modules/onnxruntime-web/dist/ort-wasm-simd-threaded.jsep.wasm lib/
```

## ğŸ¤– Model Details

| Property | Value |
|----------|-------|
| **Model** | `onnx-community/roberta-base-openai-detector-ONNX` |
| **Base** | `openai-community/roberta-base-openai-detector` |
| **Task** | Binary text classification (Real vs Fake) |
| **Quantization** | INT8 (`q8`) |
| **Runtime** | ONNX Runtime Web (WASM backend, single-threaded) |

> âš ï¸ **Disclaimer:** This model was trained to detect GPT-2 generated text. It may not accurately detect text from newer models (GPT-4, Claude, etc.). Results should not be used as definitive proof of AI authorship.

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

## ğŸ¤ Contributing

Contributions are welcome! Please read the [Contributing Guidelines](CONTRIBUTING.md) before submitting a PR.

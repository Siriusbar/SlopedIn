<p align="center">
  <img src="icons/icon128.png" alt="SlopedIn Logo" width="100" />
</p>

<h1 align="center">SlopedIn</h1>

<p align="center">
  <strong>AI Content Detector for LinkedIn</strong><br/>
  A Chrome extension that flags AI-generated posts directly in your feed ‚Äî 100% local, zero data leaves your browser.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/manifest-v3-blue" alt="Manifest V3" />
  <img src="https://img.shields.io/badge/inference-local-green" alt="Local Inference" />
  <img src="https://img.shields.io/badge/license-MIT-yellow" alt="MIT License" />
</p>

---

## ‚ú® Features

- üîç **Real-time detection** ‚Äî scans LinkedIn posts as you scroll
- üß† **Local AI inference** ‚Äî runs a RoBERTa model entirely in your browser via [Transformers.js](https://huggingface.co/docs/transformers.js)
- üîí **Privacy first** ‚Äî no data sent to external servers, ever
- üè∑Ô∏è **Visual badges** ‚Äî color-coded labels on each post (üü¢ Human ¬∑ üî¥ AI-generated)
- ‚ö° **Toggle on/off** ‚Äî enable or disable detection from the popup

## üñ•Ô∏è Screenshots

| Popup | Feed Badge |
|-------|------------|
| Clean dark-mode popup with on/off toggle | Posts get a colored badge with confidence score |

## üèóÔ∏è Architecture

```
LinkedIn Tab                     Extension (background)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   message    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ content.js  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ background.js          ‚îÇ
‚îÇ (DOM scan)  ‚îÇ              ‚îÇ (service worker)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                      ‚îÇ message
                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                             ‚îÇ offscreen.html          ‚îÇ
                             ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
                             ‚îÇ ‚îÇ offscreen.js        ‚îÇ  ‚îÇ
                             ‚îÇ ‚îÇ Transformers.js     ‚îÇ  ‚îÇ
                             ‚îÇ ‚îÇ + ONNX Runtime WASM ‚îÇ  ‚îÇ
                             ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

- **content.js** ‚Äî observes the LinkedIn DOM, extracts post text, injects badges
- **background.js** ‚Äî service worker that manages the offscreen document lifecycle
- **offscreen.js** ‚Äî loads the AI model and runs inference using ONNX Runtime (WebAssembly)
- **worker.js** ‚Äî standalone inference worker (unused in current architecture, kept for reference)

## üöÄ Installation

### Prerequisites
- Google Chrome (v116+)
- Node.js & npm (only needed to rebuild the bundle)

### Load as unpacked extension

1. **Clone the repo**
   ```bash
   git clone https://github.com/Siriusbar/SlopedIn.git
   cd SlopedIn
   ```

2. **Install dependencies** (for bundled library)
   ```bash
   npm install
   ```

3. **Open Chrome** and navigate to `chrome://extensions`

4. Enable **Developer mode** (top-right toggle)

5. Click **Load unpacked** and select the `SlopedIn` directory

6. Navigate to [linkedin.com](https://www.linkedin.com/feed/) ‚Äî posts will be scanned automatically

> **Note:** The first run downloads the AI model (~120 MB) from HuggingFace. This is cached by the browser for subsequent loads.

## ‚öôÔ∏è How It Works

1. `content.js` uses a `MutationObserver` to detect new posts in the LinkedIn feed
2. Post text is extracted and sent to `background.js` via `chrome.runtime.sendMessage`
3. `background.js` forwards the request to an offscreen document
4. `offscreen.js` runs the [`onnx-community/roberta-base-openai-detector-ONNX`](https://huggingface.co/onnx-community/roberta-base-openai-detector-ONNX) model using Transformers.js with ONNX Runtime (WASM backend)
5. The result (label + confidence) is sent back and displayed as a badge on the post

## üìÅ Project Structure

```
SlopedIn/
‚îú‚îÄ‚îÄ manifest.json          # Chrome extension manifest (MV3)
‚îú‚îÄ‚îÄ background.js          # Service worker ‚Äì offscreen doc lifecycle
‚îú‚îÄ‚îÄ offscreen.html         # Hosts the inference script
‚îú‚îÄ‚îÄ offscreen.js           # AI model loading & inference
‚îú‚îÄ‚îÄ content.js             # DOM observation & badge injection
‚îú‚îÄ‚îÄ styles.css             # Badge styling
‚îú‚îÄ‚îÄ popup.html             # Extension popup UI
‚îú‚îÄ‚îÄ popup.js               # Toggle enable/disable
‚îú‚îÄ‚îÄ worker.js              # Standalone worker (reference)
‚îú‚îÄ‚îÄ icons/
‚îÇ   ‚îú‚îÄ‚îÄ icon.svg           # Source icon
‚îÇ   ‚îú‚îÄ‚îÄ icon16.png
‚îÇ   ‚îú‚îÄ‚îÄ icon48.png
‚îÇ   ‚îî‚îÄ‚îÄ icon128.png
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ transformers.bundle.js              # Bundled Transformers.js + ONNX Runtime
‚îÇ   ‚îú‚îÄ‚îÄ ort-wasm-simd-threaded.jsep.mjs     # ONNX WASM JS proxy
‚îÇ   ‚îî‚îÄ‚îÄ ort-wasm-simd-threaded.jsep.wasm    # ONNX WASM binary (~22 MB)
‚îî‚îÄ‚îÄ package.json
```

## üîß Rebuilding the Bundle

If you need to update Transformers.js or ONNX Runtime:

```bash
# Install/update dependencies
npm install @huggingface/transformers@latest

# Bundle with esbuild
npx esbuild node_modules/@huggingface/transformers/src/transformers.js \
  --bundle --format=esm --outfile=lib/transformers.bundle.js \
  --platform=browser --target=es2020 --minify

# Copy ONNX runtime files
cp node_modules/onnxruntime-web/dist/ort-wasm-simd-threaded.jsep.mjs lib/
cp node_modules/onnxruntime-web/dist/ort-wasm-simd-threaded.jsep.wasm lib/
```

## ü§ñ Model Details

| Property | Value |
|----------|-------|
| **Model** | `onnx-community/roberta-base-openai-detector-ONNX` |
| **Base** | `openai-community/roberta-base-openai-detector` |
| **Task** | Binary text classification (Real vs Fake) |
| **Quantization** | INT8 (`q8`) |
| **Runtime** | ONNX Runtime Web (WASM backend, single-threaded) |

> ‚ö†Ô∏è **Disclaimer:** This model was trained to detect GPT-2 generated text. It may not accurately detect text from newer models (GPT-4, Claude, etc.). Results should not be used as definitive proof of AI authorship.

## üìú License

This project is licensed under the [MIT License](LICENSE).

## ü§ù Contributing

Contributions are welcome! Please read the [Contributing Guidelines](CONTRIBUTING.md) before submitting a PR.
